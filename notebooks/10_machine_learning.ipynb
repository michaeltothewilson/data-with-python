{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c207a189-10d9-46a0-b15a-b9c4860111e4",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning with California Housing Dataset\n",
    "\n",
    "<center><img src=\"../images/stock/pexels-pixabay-247819 (1).jpg\"></center>\n",
    "\n",
    "This notebook provides an introductory lesson to Machine Learning (ML) using the California Housing dataset. \n",
    "\n",
    "We will cover fundamental concepts,\n",
    "the typical ML workflow, and a practical example of building a regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3759ab53-ef39-434b-8eae-8607712b8a56",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "Machine Learning is a subset of Artificial Intelligence (AI) that enables systems\n",
    "to learn from data, identify patterns, and make decisions or predictions with\n",
    "minimal human intervention. \n",
    "\n",
    "Instead of being explicitly programmed, ML models\n",
    "\"learn\" from data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b224855-8f78-47af-84fb-d9ac238b3aaf",
   "metadata": {},
   "source": [
    "## Types of Machine Learning\n",
    "\n",
    "1.  **Supervised Learning:**\n",
    "    * **Concept:** The model learns from labeled data, meaning the input data\n",
    "        (features) is paired with the correct output (labels or targets).\n",
    "    * **Goal:** To predict an output based on new, unseen input data.\n",
    "    * **Examples:**\n",
    "        * **Regression:** Predicting a continuous value (house prices, temperature, etc).\n",
    "        * **Classification:** Predicting a categorical label (spam/not spam, dog/cat, etc).\n",
    "\n",
    "2.  **Unsupervised Learning:**\n",
    "    * **Concept:** The model learns from unlabeled data, finding hidden patterns\n",
    "        or structures within the data without explicit guidance.\n",
    "    * **Goal:** To discover underlying structures or representations in the data.\n",
    "    * **Examples:**\n",
    "        * **Clustering:** Grouping similar data points together (customer segmentation, etc).\n",
    "        * **Dimensionality Reduction:** Reducing the number of features while retaining\n",
    "            important information.\n",
    "\n",
    "3.  **Reinforcement Learning:**\n",
    "    * **Concept:** An agent learns to make decisions by performing actions in an\n",
    "        environment and receiving rewards or penalties.\n",
    "    * **Goal:** To maximize cumulative reward over time.\n",
    "    * **Examples:** Game playing (AlphaGo), robotics, autonomous driving.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c26e4-7123-4391-aca8-cd358eea14f3",
   "metadata": {},
   "source": [
    "## The Machine Learning Workflow\n",
    "\n",
    "The typical ML workflow involves several stages:\n",
    "\n",
    "1.  **Problem Definition:** Clearly define what you want to achieve with ML.\n",
    "2.  **Data Collection:** Gather relevant data.\n",
    "3.  **Data Preprocessing/Cleaning:** Handle missing values, outliers, transform data,\n",
    "    feature engineering. This is often the most time-consuming step.\n",
    "4.  **Feature Selection/Engineering:** Choosing the most relevant features or creating new ones.\n",
    "5.  **Model Selection:** Choosing an appropriate ML algorithm based on the problem type\n",
    "    (e.g., Linear Regression for continuous prediction, Logistic Regression for classification).\n",
    "6.  **Training:** Feeding the preprocessed data to the chosen model so it can learn patterns.\n",
    "7.  **Evaluation:** Assessing the model's performance on unseen data using appropriate metrics.\n",
    "8.  **Hyperparameter Tuning:** Optimizing model parameters that are not learned from data.\n",
    "9.  **Deployment:** Integrating the trained model into an application or system.\n",
    "10. **Monitoring & Maintenance:** Continuously monitoring the model's performance and retraining if necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c00b8-a9bf-43e8-810a-d1853f96a700",
   "metadata": {},
   "source": [
    "## Practical Example: Predicting California Housing Prices\n",
    "\n",
    "In this example, we will use the California Housing dataset, a classic dataset for regression tasks. Our goal is to predict the median house value for districts in California based on various features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ba46a-09b3-413f-8602-46c24d1bc151",
   "metadata": {},
   "source": [
    "### 1. Import Necessary Libraries\n",
    "\n",
    "We will import \n",
    "\n",
    "* `numpy` for numerical operations\n",
    "* `pandas` for data manipulation\n",
    "* `matplotlib.pyplot` and `seaborn` for visualization\n",
    "* `sklearn`for dataset loading, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd2ac42-c717-473f-8342-abce036728ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Begin Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set plot style for better aesthetics\n",
    "sns.set_style(\"whitegrid\")\n",
    "## End Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3cb25-d993-4f0f-a4db-e2c4d4a84104",
   "metadata": {},
   "source": [
    "### 2. Load the California Housing Dataset\n",
    "\n",
    "The California Housing dataset is readily available in `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6955402e-ff39-40c2-b88c-ca6ffa0a12b8",
   "metadata": {},
   "source": [
    "### 2. Load the California Housing Dataset\n",
    "\n",
    "Many common datasets are already built into machine learning libraries, making them easy to access. The California Housing dataset is one of them, available through `scikit-learn`.\n",
    "\n",
    "This dataset was derived from the 1990 U.S. census, using one row per census block group.\n",
    "\n",
    "A block group is the smallest geographical unit for which the U.S.\n",
    "Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n",
    "\n",
    "Each row of the dataset represents a single block group:\n",
    "* __MedInc__:        median income in block group\n",
    "* __HouseAge__:     median house age in block group\n",
    "* __AveRooms__:      average number of rooms per household\n",
    "* __AveBedrms__:     average number of bedrooms per household\n",
    "* __Population__:    block group population\n",
    "* __AveOccup__:     average number of household members\n",
    "* __Latitude__:      block group latitude\n",
    "* __Longitude__:     block group longitude\n",
    "\n",
    "**In the cell below:**\n",
    "* Load the dataset into a variable named `california_housing` using `fetch_california_housing(as_frame=True)`.\n",
    "* Create `X` from `california_housing.data` (these are your features).\n",
    "* Create `y` from `california_housing.target` (this is what you'll predict).\n",
    "* Check the dimensions by printing the `.shape` of `X` and `y`.\n",
    "* Get a quick look at your data by displaying the first few rows of `X` and `y` using `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97329dbc-150a-4b63-b89e-8d03a145cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Begin Example\n",
    "california_housing = fetch_california_housing(as_frame=True)\n",
    "X = california_housing.data  # Features\n",
    "y = california_housing.target # Target (median house value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1078e80d-883c-4c1e-acc7-5b373eb9a9f4",
   "metadata": {},
   "source": [
    "### 3.1 Data Exploration: Getting to Know the Data\n",
    "\n",
    "<center><img src=\"../images/stock/pexels-cottonbro-5473955.jpg\"></center>\n",
    "\n",
    "\n",
    "It's crucial to understand your data before trying to build a model. Let's start by looking at some basic numbers and visualizing distributions.\n",
    "\n",
    "**In the cell below:**\n",
    "\n",
    "* __Get Descriptive Statistics:__ Use the `.describe()` method on your features (`X`) to see a summary of their central tendency, dispersion, and shape.\n",
    "* __Visualize All Distributions:__ Create histograms for all columns in your `california_housing.frame`. This will include both your features (like `MedInc`, `HouseAge`, etc.) and your target variable (`MedHouseVal`). You can use the built-in `.hist()` method available on pandas DataFrames, which works well with `matplotlib`.\n",
    "* Consider adjusting the `figsize` and `bins` parameters to make the histograms clear and readable.\n",
    "* Add `edgecolor=\"black\"` for better visual separation of bars.\n",
    "* Use `plt.subplots_adjust` to manage spacing between plots, and `plt.suptitle` for an overall title.\n",
    "* Call `plt.tight_layout()` to prevent labels from overlapping.\n",
    "\n",
    "**After running the code, what do you notice about the histograms?**\n",
    "\n",
    "* Look at `MedInc` (Median Income) and `MedHouseVal` (Median House Value). Do you see a long \"tail\" on one side, or do they stop abruptly? (note that `MedHouseVal` was capped at $500,000 for simplicity in the original dataset, which means values above 5.0 are shown as 5.0).\n",
    "* Which features seem to have a lot of data grouped together, and which are more spread out?\n",
    "* Do any of them look like a bell curve? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ea48b-a4c5-4c85-9f7b-511531871eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Begin Example\n",
    "# Descriptive Statistics\n",
    "\n",
    "\n",
    "## End Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f5e6d0-648d-4fcd-86ca-9d9e0afb5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Begin Example\n",
    "# Viz\n",
    "california_housing.frame.hist(figsize=, \n",
    "                              bins=, \n",
    "                              edgecolor=)\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.4)\n",
    "plt.suptitle(\"Distribution of California Housing Features\")\n",
    "plt.tight_layout()\n",
    "## End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad13fe15-ba89-44b8-8de6-e4fd9a616c7f",
   "metadata": {},
   "source": [
    "### 3.2 Data Exploration: Geographical Distribution of House Values\n",
    "\n",
    "Let's use a scatter plot to visualize house values on a map of California. This will help us see if there are any geographical patterns.\n",
    "\n",
    "* The **horizontal position (x-axis)** of each dot tells us its **Longitude** (how far east or west it is).\n",
    "* The **vertical position (y-axis)** of each dot tells us its **Latitude** (how far north or south it is).\n",
    "* We can also use the **size** and **color** of each dot to show the **Median House Value (`MedHouseVal`)** of that neighborhood. Bigger and brighter dots will represent higher values.\n",
    "\n",
    "**In the cell below:**\n",
    "\n",
    "* __Generate the Scatter Plot:__\n",
    "    * Use `sns.scatterplot()` to plot `Longitude` on the x-axis and `Latitude` on the y-axis.\n",
    "    * Map `MedHouseVal` to both the `size` and `hue` (color) of the points.\n",
    "    * Set `palette=\"viridis\"` for a clear color gradient and `alpha=0.5` to help see overlapping points.\n",
    "* __Adjust the Legend:__ Position the legend so it doesn't obstruct the data using `loc`.\n",
    "* __Add a Title:__ Give your plot a descriptive title that reflects what it's showing.\n",
    "\n",
    "**What do you notice about the plot?**\n",
    "* Are there any bright, large clusters of dots? Where are they located?\n",
    "* Do smaller, darker dots appear in different areas?\n",
    "* What does this tell us about housing prices and location in California?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d169a-db6b-4f83-8ac8-5396b2797b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Begin Example\n",
    "sns.scatterplot(data=,\n",
    "                x=,\n",
    "                y=,\n",
    "                size=,\n",
    "                hue=,\n",
    "                palette=,\n",
    "                alpha=)\n",
    "\n",
    "plt.legend(title=, bbox_to_anchor=, loc=\"best\")\n",
    "plt.title()\n",
    "## End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9477721-717d-4d93-a646-a62985cd5ae4",
   "metadata": {},
   "source": [
    "### 4. Splitting the Data into Training and Testing Sets\n",
    "\n",
    "This is a critical step in Machine Learning! You need to split your data into two parts:\n",
    "* The **Training Set:** This is the data your model will \"learn\" from.\n",
    "* The **Testing Set:** This is data the model has **never seen before**. You'll use it to evaluate how well your model truly performs and if it can make good predictions on new, real-world data.\n",
    "\n",
    "We typically use about 70-80% of the data for training and 20-30% for testing. Using `random_state` ensures that if you run your code multiple times, you'll get the same split, which helps with reproducibility.\n",
    "\n",
    "**In the cell below:**\n",
    "\n",
    "Use the `train_test_split` function from `sklearn.model_selection` to divide your `X` (features) and `y` (target) data. When calling the function:\n",
    "\n",
    "* Set `test_size=0.2` to allocate 20% of the data for testing.\n",
    "* Set `random_state=42` to ensure that if you run the code multiple times, you'll get the exact same split, which is great for reproducibility.\n",
    "\n",
    "This function will return four separate items, so you'll need to create four variables to capture them:\n",
    "\n",
    "* `X_train`: Your training features.\n",
    "* `X_test`: Your testing features.\n",
    "* `y_train`: Your training target values.\n",
    "* `y_test`: Your testing target values.\n",
    "\n",
    "\n",
    "Syntax Example:\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(Your_X_Data,\n",
    "                                                    Your_y_Data, \n",
    "                                                    test_size=float, \n",
    "                                                    random_state=int)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12eff0-e72c-4cb7-9299-ab66645c787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Begin Example\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fcbad-d5c0-49d8-a9ac-cedaf198f3df",
   "metadata": {},
   "source": [
    "### 5. Model Selection and Training\n",
    "\n",
    "For this regression problem (predicting a continuous number), we'll start with a simple but powerful model: **Linear Regression**. This model tries to find the best straight line (or flat surface in multiple dimensions) that fits your data.\n",
    "\n",
    "**In the cell below:**\n",
    "* __Create an Instance:__ Create a new, empty model object by calling `LinearRegression()`. You'll typically assign this to a variable like `model`.\n",
    "* __Train the Model:__ Now, use the `fit()` method on your `model` instance. Provide your training features (`X_train`) and your corresponding training target values (`y_train`) to this method. During this step, the model will analyze your training data and learn the underlying patterns and relationships.\n",
    "\n",
    "Syntax Example:\n",
    "\n",
    "```python\n",
    "model = LinearRegression()\n",
    "model.fit(Your_X_Train, Your_Y_Train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3122f2b-d851-4f53-aa8c-20031c1523f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Begin Example\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91737604-0960-46cb-b24c-7177256f3b1a",
   "metadata": {},
   "source": [
    "### 6. Making Predictions\n",
    "\n",
    "<center><img src=\"../images/stock/pexels-googledeepmind-17483868.jpg\"></center>\n",
    "\n",
    "\n",
    "Once your model is trained, it's ready to make guesses! You'll ask it to predict the house values for the `X_test` data (the data it has never seen before).\n",
    "\n",
    "**In the cell below:**\n",
    "* __Generate Predictions:__ Use your trained `model`'s `predict()` method. This method takes the features of the data you want to predict on as input.\n",
    "* __Input Test Features:__ Pass your `X_test` data into the `predict()` method.\n",
    "* __Store Predictions:__ Assign the output of the `predict()` method to a new variable, commonly named `y_pred`.\n",
    "* __Compare Actual vs. Predicted (Initial Look):__ To get an immediate sense of your model's performance, print the first few actual values from your `y_test` and compare them side-by-side with the corresponding `y_pred` values.\n",
    "\n",
    "\n",
    "This comparison can give you an early qualitative feel for how accurate the predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5825a3-0614-4b48-a29f-11b79a28ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Begin Example\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe5f2c-1424-437b-ac34-6fdfd13e8c64",
   "metadata": {},
   "source": [
    "### 7. Model Evaluation: Assessing Performance with R-squared\n",
    "After training your model and making predictions, the next critical step is to evaluate how well your model actually performed. For regression problems, a common and insightful metric is R-squared ($R^2$).\n",
    "\n",
    "* R-squared ($R^2$): This metric represents the proportion of the variance in the dependent variable (your y or target) that can be predicted from your independent variables (your X or features). Essentially, it tells you how well your model's predictions explain the variability in the actual outcomes.\n",
    "    * $R^2$ values range from 0 to 1.\n",
    "        * An $R^2$ of 1 indicates a perfect fit, meaning your model explains 100% of the variance in the target variable.\n",
    "        * An $R^2$ of 0 indicates that your model explains none of the variance, performing no better than simply predicting the average of the target values.\n",
    "\n",
    "In the cell below, let's calculate the R-squared score for your model's predictions:\n",
    "\n",
    "* __Calculate R-squared:__ Call the `r2_score()` function.\n",
    "    * Pass your actual test target values (`y_test`) as the first argument.\n",
    "    * Pass your model's predictions (`y_pred`) as the second argument.\n",
    "* __Store and Print:__ Store the returned score in a variable named `r2`, and then print it, formatted to two decimal places.\n",
    "\n",
    "After running the code, what does this R-squared value tell you about your model's performance?\n",
    "\n",
    "* Is the value close to 1, indicating a strong fit?\n",
    "* Is it closer to 0, suggesting the model isn't explaining much of the variance?\n",
    "\n",
    "What does this number imply about how well your Linear Regression model predicts median house values in California based on the given features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a2242-ef51-4fe4-8d95-cf5e40aa9f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Begin Example\n",
    "\n",
    "\n",
    "\n",
    "## End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48a3359-90d5-4a1c-b992-455132cc7634",
   "metadata": {},
   "source": [
    "### 8. Visualization of Predictions vs. Actual Values\n",
    "\n",
    "A great way to visually assess your model is to plot its predictions against the actual values. If your model were perfect, all the dots would fall exactly on a 45-degree diagonal line. The closer your dots are to that line, the better your model is!\n",
    "\n",
    "**In the cell below:**\n",
    "\n",
    "* __Set up the Plot:__ Initialize a new figure with a suitable `figsize` using `plt.figure()`.\n",
    "* __Create the Scatter Plot:__ Use `plt.scatter()`.\n",
    "    * Place your actual test target values (`y_test`) on the `x-axis`.\n",
    "    * Place your model's predicted values (`y_pred`) on the y-axis.\n",
    "    * Adjust `alpha` to help visualize dense areas of points.\n",
    "* __Draw the Ideal Line:__ Add a diagonal line using `plt.plot()`. This line will stretch from the minimum to the maximum of your target values, serving as a visual benchmark for a perfect prediction. Use a dashed red line (`'r--'`) for clear visibility.\n",
    "* __Add Labels and Title:__ Label your x-axis, y-axis, and give the plot a descriptive title.\n",
    "* __Enhance Readability:__ Add a grid with `plt.grid(True)` for easier interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d210e-78ad-4b2f-8c2a-e2c521658bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Begin Example\n",
    "plt.figure(figsize=()\n",
    "plt.scatter(\"xaxis here\",\n",
    "            \"yaxis here\", \n",
    "            alpha=)\n",
    "\n",
    "# Diagonal Line\n",
    "plt.plot([y_test.min(), y_test.max()], \n",
    "         [y_test.min(), y_test.max()], \n",
    "         'r--', \n",
    "         lw=2)\n",
    "\n",
    "            \n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "plt.title()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "## End Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae149e-3cc7-4eda-bfde-a65e31ca4c11",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've just completed a hands-on exploration of a fundamental\n",
    "Machine Learning workflow. You've learned how to:\n",
    "\n",
    "* Understand the basics of ML types and its typical steps.\n",
    "* Load and explore a real-world dataset.\n",
    "* Prepare data by splitting it into training and testing sets.\n",
    "* Train a simple regression model.\n",
    "* Make predictions with your model.\n",
    "* Evaluate your model's performance using common metrics.\n",
    "* Visualize your results to gain insights.\n",
    "\n",
    "This is truly just the beginning of your journey into Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a165a-c5c5-4195-a2f5-e93220096501",
   "metadata": {},
   "source": [
    "### How Can We Improve This Model?\n",
    "\n",
    "<center><img src=\"../images/stock/pexels-pavel-danilyuk-8439001.jpg\"></center>\n",
    "\n",
    "Now that you've seen a basic model in action, the next exciting step is to think about **how we could make it even better**. Consider these questions and discuss them with your classmates:\n",
    "\n",
    "1.  **Could we get more data?** Often, having more diverse and relevant data can help a model learn better patterns and make more accurate predictions, especially if your current dataset is small or doesn't cover all scenarios.\n",
    "2.  **Could we use a different type of model?** Linear Regression assumes a straight-line relationship. What if the relationship between features and house prices isn't a straight line? (Hint: In `sklearn`, explore `ensemble` models like Decision Trees or Random Forests, or even `neural_network` models).\n",
    "3.  **Are all the features equally important?** Should we try to use all the features, or could some be combined or transformed? (Hint: Sometimes creating new features from existing ones – this is called \"feature engineering\" – or selecting only the most impactful ones can improve results).\n",
    "4.  **Does the \"scale\" of our data matter?** Some features like 'population' are very large numbers, while others like 'average rooms' are small. Could this difference in scale affect how the model learns? (Hint: Look into 'feature scaling' or 'normalization' techniques in `sklearn.preprocessing`).\n",
    "5.  **How could we be more sure our model isn't just \"memorizing\" the training data?** Our model works okay on the test set, but what if it just got \"lucky\" on this particular split? How can we make our evaluation more robust? (Hint: Research 'cross-validation' techniques).\n",
    "\n",
    "These are just a few ideas to get you thinking about the exciting next steps in improving machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e68dd-28d7-44f1-a0ab-f51d081b36e3",
   "metadata": {},
   "source": [
    "### Where to Learn More\n",
    "\n",
    "Official Documentation Resources:\n",
    "* Seaborn (Statistical Data Visualization):\n",
    "\n",
    "__Main Documentation:__ [https://seaborn.pydata.org/](https://seaborn.pydata.org/)\n",
    "\n",
    "This site offers complete API references, detailed tutorials, and an extensive gallery of examples with accompanying code.\n",
    "\n",
    "* Scikit-learn (Machine Learning in Python):\n",
    "\n",
    "__Main Documentation:__ [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)\n",
    "\n",
    "Here you'll find thorough explanations of all algorithms, preprocessing methods, model selection techniques, and evaluation metrics. It includes a user guide and an examples gallery to help you understand implementation and application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
